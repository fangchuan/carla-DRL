Logging to logs/openai-2019-03-14-15-19-23-564521
--------------------------------
| episodes          | 20       |
| mean_100ep_reward | -0.13    |
| steps             | 3908     |
| time_exploring    | 61       |
--------------------------------
Saving model due to mean reward increase: None -> -0.13
--------------------------------
| episodes          | 40       |
| mean_100ep_reward | -0.17    |
| steps             | 7409     |
| time_exploring    | 27       |
--------------------------------
--------------------------------
| episodes          | 60       |
| mean_100ep_reward | -0.36    |
| steps             | 9796     |
| time_exploring    | 3        |
--------------------------------
--------------------------------
| episodes          | 80       |
| mean_100ep_reward | -0.4     |
| steps             | 11929    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.41    |
| steps             | 14391    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.41    |
| steps             | 14460    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.41    |
| steps             | 14662    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.41    |
| steps             | 14864    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.41    |
| steps             | 15066    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.41    |
| steps             | 15268    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.42    |
| steps             | 15359    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.42    |
| steps             | 15561    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.42    |
| steps             | 15763    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.43    |
| steps             | 15861    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.43    |
| steps             | 16024    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.42    |
| steps             | 16226    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.42    |
| steps             | 16398    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.42    |
| steps             | 16493    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.42    |
| steps             | 16594    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.43    |
| steps             | 16713    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.45    |
| steps             | 16827    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.44    |
| steps             | 17029    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.43    |
| steps             | 17231    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.43    |
| steps             | 17357    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.42    |
| steps             | 17559    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.42    |
| steps             | 17761    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.42    |
| steps             | 17960    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.42    |
| steps             | 18162    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.41    |
| steps             | 18364    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.4     |
| steps             | 18566    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.4     |
| steps             | 18715    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.39    |
| steps             | 18917    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.39    |
| steps             | 19119    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.39    |
| steps             | 19283    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.39    |
| steps             | 19485    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.38    |
| steps             | 19687    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.38    |
| steps             | 19814    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.38    |
| steps             | 19926    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.36    |
| steps             | 20128    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.37    |
| steps             | 20266    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.38    |
| steps             | 20407    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.36    |
| steps             | 20605    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.36    |
| steps             | 20760    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.36    |
| steps             | 20898    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.38    |
| steps             | 21034    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.36    |
| steps             | 21236    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.36    |
| steps             | 21438    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.37    |
| steps             | 21546    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.35    |
| steps             | 21748    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.35    |
| steps             | 21834    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.34    |
| steps             | 22008    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.34    |
| steps             | 22188    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.34    |
| steps             | 22340    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.32    |
| steps             | 22454    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.32    |
| steps             | 22612    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.31    |
| steps             | 22730    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.31    |
| steps             | 22840    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.3     |
| steps             | 23042    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.29    |
| steps             | 23175    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.28    |
| steps             | 23377    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.29    |
| steps             | 23518    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.29    |
| steps             | 23636    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.28    |
| steps             | 23838    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.29    |
| steps             | 23950    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.28    |
| steps             | 24104    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.27    |
| steps             | 24306    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.28    |
| steps             | 24508    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.28    |
| steps             | 24631    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.3     |
| steps             | 24779    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.3     |
| steps             | 24981    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.29    |
| steps             | 25154    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.29    |
| steps             | 25345    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.28    |
| steps             | 25547    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.28    |
| steps             | 25649    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.26    |
| steps             | 25851    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.25    |
| steps             | 26053    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.23    |
| steps             | 26255    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.22    |
| steps             | 26457    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.21    |
| steps             | 26646    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.19    |
| steps             | 26772    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.18    |
| steps             | 26974    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.17    |
| steps             | 27176    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.17    |
| steps             | 27378    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.17    |
| steps             | 27528    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.15    |
| steps             | 27730    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.15    |
| steps             | 27845    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.14    |
| steps             | 28047    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.12    |
| steps             | 28199    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: -0.13 -> -0.12
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.11    |
| steps             | 28387    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: -0.12 -> -0.11
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.1     |
| steps             | 28541    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: -0.11 -> -0.1
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.09    |
| steps             | 28743    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: -0.1 -> -0.09
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.07    |
| steps             | 28945    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: -0.09 -> -0.07
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.06    |
| steps             | 29147    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: -0.07 -> -0.06
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.05    |
| steps             | 29349    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: -0.06 -> -0.05
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.05    |
| steps             | 29551    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.06    |
| steps             | 29712    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.05    |
| steps             | 29860    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.04    |
| steps             | 30021    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: -0.05 -> -0.04
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.02    |
| steps             | 30223    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: -0.04 -> -0.02
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.02    |
| steps             | 30356    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.01    |
| steps             | 30558    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: -0.02 -> -0.01
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.01    |
| steps             | 30760    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0       |
| steps             | 30962    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: -0.01 -> -0.0
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.01     |
| steps             | 31164    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: -0.0 -> 0.01
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.03     |
| steps             | 31366    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.01 -> 0.03
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.01     |
| steps             | 31529    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.02     |
| steps             | 31678    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.03     |
| steps             | 31834    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.03     |
| steps             | 32036    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.03     |
| steps             | 32118    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.04     |
| steps             | 32320    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.03 -> 0.04
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.04     |
| steps             | 32522    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.06     |
| steps             | 32715    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.04 -> 0.06
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.08     |
| steps             | 32917    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.06 -> 0.08
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.08     |
| steps             | 33119    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.08     |
| steps             | 33321    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.09     |
| steps             | 33522    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.08 -> 0.09
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.1      |
| steps             | 33724    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.09 -> 0.1
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.1      |
| steps             | 33885    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.11     |
| steps             | 33995    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.1 -> 0.11
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.11     |
| steps             | 34156    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.12     |
| steps             | 34358    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.11 -> 0.12
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.1      |
| steps             | 34483    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.12     |
| steps             | 34636    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.13     |
| steps             | 34746    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.12 -> 0.13
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.14     |
| steps             | 34906    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.13 -> 0.14
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.15     |
| steps             | 35054    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.14 -> 0.15
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.15     |
| steps             | 35256    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.16     |
| steps             | 35458    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.15 -> 0.16
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.18     |
| steps             | 35622    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.16 -> 0.18
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.18     |
| steps             | 35761    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.19     |
| steps             | 35921    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.18 -> 0.19
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.19     |
| steps             | 36110    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.2      |
| steps             | 36312    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.19 -> 0.2
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.21     |
| steps             | 36514    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.2 -> 0.21
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.21     |
| steps             | 36716    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.22     |
| steps             | 36876    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.21 -> 0.22
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.22     |
| steps             | 36984    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.21     |
| steps             | 37142    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.22     |
| steps             | 37344    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.23     |
| steps             | 37546    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.22 -> 0.23
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.22     |
| steps             | 37748    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.24     |
| steps             | 37950    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.23 -> 0.24
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.25     |
| steps             | 38086    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.24 -> 0.25
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.28     |
| steps             | 38288    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.25 -> 0.28
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.28     |
| steps             | 38490    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.28     |
| steps             | 38603    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.3      |
| steps             | 38805    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.28 -> 0.3
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.3      |
| steps             | 39007    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.3      |
| steps             | 39122    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.32     |
| steps             | 39265    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.3 -> 0.32
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.32     |
| steps             | 39467    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.35     |
| steps             | 39622    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.32 -> 0.35
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.35     |
| steps             | 39824    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.37     |
| steps             | 40003    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.35 -> 0.37
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.38     |
| steps             | 40205    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.37 -> 0.38
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.39     |
| steps             | 40360    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.38 -> 0.39
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.4      |
| steps             | 40562    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.39 -> 0.4
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.41     |
| steps             | 40714    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.4 -> 0.41
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.41     |
| steps             | 40916    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.43     |
| steps             | 41118    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.41 -> 0.43
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.44     |
| steps             | 41294    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.43 -> 0.44
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.44     |
| steps             | 41478    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.45     |
| steps             | 41680    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.44 -> 0.45
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.46     |
| steps             | 41829    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.45 -> 0.46
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.46     |
| steps             | 42031    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.47     |
| steps             | 42176    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.46 -> 0.47
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.48     |
| steps             | 42310    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.47 -> 0.48
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.5      |
| steps             | 42475    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.48 -> 0.5
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.51     |
| steps             | 42677    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.5 -> 0.51
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.51     |
| steps             | 42846    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.51     |
| steps             | 43048    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.52     |
| steps             | 43180    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.51 -> 0.52
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.54     |
| steps             | 43382    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.52 -> 0.54
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.53     |
| steps             | 43575    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.52     |
| steps             | 43692    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.52     |
| steps             | 43854    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.52     |
| steps             | 44056    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.51     |
| steps             | 44148    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.51     |
| steps             | 44310    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.53     |
| steps             | 44477    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.54     |
| steps             | 44626    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.54     |
| steps             | 44778    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.56     |
| steps             | 44960    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.54 -> 0.56
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.57     |
| steps             | 45150    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.56 -> 0.57
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.57     |
| steps             | 45317    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.57     |
| steps             | 45519    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.57     |
| steps             | 45721    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.57     |
| steps             | 45923    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.58     |
| steps             | 46056    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.57 -> 0.58
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.58     |
| steps             | 46234    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.58     |
| steps             | 46436    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.58     |
| steps             | 46607    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.57     |
| steps             | 46809    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.58     |
| steps             | 46990    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.59     |
| steps             | 47093    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.58 -> 0.59
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.57     |
| steps             | 47234    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.55     |
| steps             | 47350    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.56     |
| steps             | 47542    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.56     |
| steps             | 47708    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.56     |
| steps             | 47910    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.56     |
| steps             | 48112    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.56     |
| steps             | 48314    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.57     |
| steps             | 48479    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.58     |
| steps             | 48650    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 48796    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.59 -> 0.6
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 48950    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 49074    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.6 -> 0.61
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 49219    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 49397    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.61 -> 0.62
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 49599    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.62 -> 0.63
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 49801    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 50003    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 50192    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 50292    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 50494    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 50683    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 50857    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 51044    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 51246    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 51448    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.63 -> 0.65
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 51646    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 51805    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.65 -> 0.67
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 52007    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 52209    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 52411    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 52569    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 52771    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 52973    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 53148    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 53350    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 53552    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 53745    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 53947    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 54080    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 54282    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 54484    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 54686    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 54888    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 55090    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 55271    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 55427    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.67 -> 0.68
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 55629    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 55831    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 55966    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 56168    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 56307    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 56509    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 56679    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 56854    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 57035    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 57152    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 57296    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 57448    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 57613    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 57778    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 57977    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 58161    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 58363    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 58430    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 58632    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 58834    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 59011    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 59185    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 59348    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 59498    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 59660    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 59844    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 60046    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 60125    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 60327    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 60458    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 60600    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 60802    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 60983    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 61146    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 61291    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 61431    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 61622    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 61788    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 61963    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 62045    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 62205    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 62366    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 62509    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 62658    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 62860    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 63017    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 63189    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 63375    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 63523    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.69     |
| steps             | 63725    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.68 -> 0.69
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 63816    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 63919    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 64087    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 64233    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.69 -> 0.7
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 64435    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.7 -> 0.71
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 64586    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.71 -> 0.74
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 64716    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 64870    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 65037    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.74 -> 0.75
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 65239    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 65386    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 65513    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 65684    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 65840    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 65971    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 66127    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 66286    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 66471    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 66622    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 66824    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 66995    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 67197    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 67399    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 67601    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 67803    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 68005    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 68154    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 68327    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 68367    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 68569    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 68664    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 68866    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 69006    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 69170    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 69261    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 69385    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 69570    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 69772    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 69917    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 70084    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 70270    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 70383    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 70552    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 70754    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 70819    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 70945    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 71147    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 71300    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 71497    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 71696    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 71851    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 72053    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.59     |
| steps             | 72127    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 72329    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 72514    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 72716    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 72906    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 73009    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 73076    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 73278    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 73349    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 73495    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 73697    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 73846    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 74018    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 74159    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 74347    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 74549    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 74724    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 74879    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 75036    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 75153    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 75344    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 75482    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 75594    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.59     |
| steps             | 75738    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.59     |
| steps             | 75884    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 76058    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 76260    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 76462    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 76651    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 76853    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 77034    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 77205    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 77337    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 77477    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 77651    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 77791    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 77993    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 78195    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 78366    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 78549    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 78751    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.6      |
| steps             | 78904    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 79090    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 79263    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 79413    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 79578    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 79780    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 79963    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 80149    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 80341    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 80508    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 80656    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 80829    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 81019    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 81192    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 81353    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 81458    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 81614    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 81757    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 81939    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 82141    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 82343    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 82545    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 82729    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 82876    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 83078    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 83260    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 83402    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.69     |
| steps             | 83539    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 83674    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 83876    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 84058    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 84232    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 84434    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 84572    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 84762    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 84893    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 85095    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 85251    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 85382    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 85553    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 85755    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 85954    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.75 -> 0.76
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 86088    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 86290    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 86456    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.76 -> 0.78
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 86658    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 86847    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 86946    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 87072    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 87222    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 87417    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 87607    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 87787    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 87930    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 88132    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 88328    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 88489    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.78 -> 0.79
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 88632    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 88805    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 88981    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 89125    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.79 -> 0.8
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 89274    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.8 -> 0.81
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 89422    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 89592    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 89735    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 89874    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 90076    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 90247    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.81 -> 0.83
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 90327    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 90455    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 90657    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 90804    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 90957    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 91097    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 91261    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 91446    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 91585    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 91748    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 91881    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 92013    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.83 -> 0.84
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 92185    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 92330    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 92512    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.84 -> 0.85
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 92688    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 92890    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 93062    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 93226    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 93355    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 93520    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.85 -> 0.86
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 93665    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 93829    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 93957    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 94129    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 94258    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 94391    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 94520    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 94681    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 94823    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 94996    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 95166    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 95360    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 95545    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 95689    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 95819    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 95960    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 96134    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 96286    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 96409    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 96536    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 96706    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 96824    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 97010    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 97182    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 97300    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 97488    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 97599    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 97745    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 97920    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 98063    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 98230    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 98362    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 98493    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 98695    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 98897    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 99066    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 99151    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 99276    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 99387    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 99574    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 99766    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 99883    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 100056   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 100222   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 100369   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 100484   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 100662   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 100861   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 101015   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 101100   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 101248   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 101398   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 101563   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 101692   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 101833   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 102031   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 102194   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 102322   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 102482   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 102630   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 102798   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 102965   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 103158   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 103349   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 103429   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 103631   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 103711   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 103840   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 103977   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 104130   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 104269   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 104425   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 104572   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 104774   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 104917   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 105073   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 105258   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 105398   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 105600   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 105763   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 105926   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 106038   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 106156   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 106358   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 106520   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 106722   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 106863   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 107029   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 107201   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 107403   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 107605   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 107769   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 107924   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 108081   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 108283   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 108485   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 108660   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 108862   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 109044   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 109188   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 109390   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 109472   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 109601   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 109803   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 109948   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 110087   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 110275   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 110477   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 110627   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 110791   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 110979   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 111152   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 111284   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 111461   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 111605   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 111714   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 111878   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 112073   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 112214   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 112356   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 112501   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 112639   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 112841   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 113031   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 113184   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 113386   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 113588   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 113721   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 113923   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 114097   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 114235   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 114321   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 114465   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 114612   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 114773   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 114910   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 115041   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 115169   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 115327   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 115492   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 115644   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 115796   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 115954   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 116156   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 116352   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 116487   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 116638   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 116763   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 116891   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 117045   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 117215   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 117387   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 117531   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.87     |
| steps             | 117700   |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.86 -> 0.87
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.87     |
| steps             | 117829   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.88     |
| steps             | 117976   |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.87 -> 0.88
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.88     |
| steps             | 118141   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 118326   |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.88 -> 0.89
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 118474   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 118676   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 118804   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 118929   |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.89 -> 0.9
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 119083   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 119205   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 119342   |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.9 -> 0.91
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 119515   |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.91 -> 0.92
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 119650   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 119812   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 119951   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.88     |
| steps             | 120068   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.88     |
| steps             | 120270   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.88     |
| steps             | 120392   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.88     |
| steps             | 120532   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 120680   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 120835   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 120998   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 121176   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 121340   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 121542   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 121677   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.88     |
| steps             | 121837   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 121963   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 122149   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 122271   |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.92 -> 0.93
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 122379   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 122509   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 122648   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 122779   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 122920   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 123066   |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.93 -> 0.94
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 123244   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 123400   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 123554   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 123686   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 123846   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 123989   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 124121   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 124234   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 124436   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 124631   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 124795   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 124958   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 125091   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 125293   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 125463   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 125643   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 125747   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 125901   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 126068   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 126199   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 126397   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 126580   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 126656   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.95     |
| steps             | 126827   |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.94 -> 0.95
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 126975   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 127170   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 127308   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.95     |
| steps             | 127468   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 127624   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 127826   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 128005   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 128138   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 128269   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.95     |
| steps             | 128398   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.95     |
| steps             | 128536   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.95     |
| steps             | 128703   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.96     |
| steps             | 128878   |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.95 -> 0.96
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.96     |
| steps             | 129021   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.98     |
| steps             | 129188   |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.96 -> 0.98
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.96     |
| steps             | 129312   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 129452   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.97     |
| steps             | 129612   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.97     |
| steps             | 129782   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.97     |
| steps             | 129911   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.96     |
| steps             | 130078   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.96     |
| steps             | 130258   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 130447   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 130636   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.95     |
| steps             | 130782   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.95     |
| steps             | 130949   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.95     |
| steps             | 131079   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.95     |
| steps             | 131229   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.95     |
| steps             | 131383   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.97     |
| steps             | 131550   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.97     |
| steps             | 131734   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.96     |
| steps             | 131936   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.96     |
| steps             | 132085   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 132227   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 132402   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 132601   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 132668   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 132853   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 132982   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 133115   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 133244   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 133386   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 133509   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 133608   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 133764   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 133913   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 134058   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 134253   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 134434   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 134585   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 134768   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 134882   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 135055   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 135172   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 135307   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 135475   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 135636   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 135789   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 135991   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 136167   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 136241   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 136443   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 136513   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 136661   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.69     |
| steps             | 136759   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 136904   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 137087   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 137222   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 137324   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 137462   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 137619   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 137791   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 137957   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 138117   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 138251   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 138441   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 138603   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 138702   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 138904   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 139001   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 139203   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 139287   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 139435   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 139591   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 139674   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 139766   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 139917   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 140104   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 140257   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 140410   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 140550   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 140689   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 140891   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 141024   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 141169   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 141281   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 141442   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 141581   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 141719   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 141858   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 142052   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 142236   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 142387   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 142579   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 142734   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 142879   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.69     |
| steps             | 143038   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 143231   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 143300   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 143469   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 143669   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 143871   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 143973   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 144047   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.61     |
| steps             | 144247   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.62     |
| steps             | 144448   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 144629   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 144816   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 144954   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 145098   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 145260   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.63     |
| steps             | 145366   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 145498   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 145627   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 145806   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 146008   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 146080   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 146245   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 146396   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 146542   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 146682   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 146826   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 147028   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 147196   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.64     |
| steps             | 147311   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.65     |
| steps             | 147472   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 147635   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 147698   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 147851   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 148036   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.67     |
| steps             | 148200   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 148266   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.66     |
| steps             | 148413   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 148563   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.68     |
| steps             | 148756   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.69     |
| steps             | 148955   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 149133   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 149294   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 149464   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 149666   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 149762   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 149946   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 150114   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 150266   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 150468   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 150597   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 150745   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 150947   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 151043   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 151172   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 151374   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 151552   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 151710   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 151859   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 152010   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 152199   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 152355   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 152530   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 152674   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 152819   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 152971   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 153136   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 153338   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 153478   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 153644   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 153745   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 153886   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 154039   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 154224   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 154406   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 154608   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 154698   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 154768   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 154970   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 155104   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 155266   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 155443   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 155576   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 155740   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 155913   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 156075   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 156235   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 156414   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 156560   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 156703   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 156905   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 157086   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 157240   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 157405   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 157584   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 157708   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 157842   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 157959   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 158138   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 158310   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 158400   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 158544   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 158673   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 158798   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 158935   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 159087   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 159226   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 159407   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 159487   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 159689   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 159854   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 159999   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 160147   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 160295   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 160430   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 160584   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 160786   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 160988   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 161157   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 161312   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 161467   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 161598   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 161719   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 161860   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 161985   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 162115   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 162317   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 162517   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 162655   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 162841   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 162997   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 163139   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 163269   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 163403   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 163578   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 163780   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 163934   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 164085   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 164205   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 164407   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 164579   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 164655   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 164811   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 164992   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 165190   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 165334   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 165462   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 165664   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 165859   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 165987   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 166082   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.87     |
| steps             | 166201   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.88     |
| steps             | 166357   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.88     |
| steps             | 166559   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 166701   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 166838   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 166970   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 167115   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 167247   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 167380   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 167546   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 167685   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 167887   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 168020   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 168163   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 168335   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 168474   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.95     |
| steps             | 168595   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 168704   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 168842   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 168979   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 169130   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 169326   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 169528   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 169730   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 169878   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.96     |
| steps             | 170080   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.98     |
| steps             | 170254   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.98     |
| steps             | 170395   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1        |
| steps             | 170535   |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.98 -> 1.0
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.02     |
| steps             | 170737   |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 1.0 -> 1.02
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.02     |
| steps             | 170865   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.99     |
| steps             | 170962   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.99     |
| steps             | 171097   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.98     |
| steps             | 171191   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.98     |
| steps             | 171290   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.97     |
| steps             | 171435   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.98     |
| steps             | 171623   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.98     |
| steps             | 171786   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.98     |
| steps             | 171908   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.97     |
| steps             | 172009   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.99     |
| steps             | 172180   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.99     |
| steps             | 172332   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1        |
| steps             | 172483   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.01     |
| steps             | 172610   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.01     |
| steps             | 172744   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.03     |
| steps             | 172946   |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 1.02 -> 1.03
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.03     |
| steps             | 173125   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.03     |
| steps             | 173270   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.03     |
| steps             | 173411   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.05     |
| steps             | 173561   |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 1.03 -> 1.05
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.05     |
| steps             | 173688   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.05     |
| steps             | 173801   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.03     |
| steps             | 173944   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.03     |
| steps             | 174106   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.02     |
| steps             | 174298   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.01     |
| steps             | 174393   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.01     |
| steps             | 174524   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.02     |
| steps             | 174678   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.01     |
| steps             | 174880   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.02     |
| steps             | 175020   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.01     |
| steps             | 175167   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1.01     |
| steps             | 175238   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1        |
| steps             | 175367   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 1        |
| steps             | 175517   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.98     |
| steps             | 175642   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.98     |
| steps             | 175784   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.98     |
| steps             | 175986   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.96     |
| steps             | 176124   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.96     |
| steps             | 176324   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.96     |
| steps             | 176478   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.96     |
| steps             | 176647   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.95     |
| steps             | 176769   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 176971   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 177068   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 177188   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 177377   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 177528   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 177706   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 177857   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 177978   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 178092   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 178236   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 178372   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 178556   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 178726   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 178881   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 179010   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 179212   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 179378   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 179580   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.94     |
| steps             | 179742   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 179897   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 180056   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 180241   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 180379   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 180516   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.92     |
| steps             | 180582   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.93     |
| steps             | 180705   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.91     |
| steps             | 180770   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 180854   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.9      |
| steps             | 181009   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.89     |
| steps             | 181211   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.88     |
| steps             | 181315   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.87     |
| steps             | 181434   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 181527   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 181653   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 181795   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 181943   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 182145   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 182282   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 182417   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 182619   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 182821   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 182984   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 183121   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 183259   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 183418   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 183541   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 183682   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 183817   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 183946   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.86     |
| steps             | 184102   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.87     |
| steps             | 184294   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 184407   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 184555   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 184701   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 184857   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 185019   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 185147   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 185298   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 185500   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.87     |
| steps             | 185616   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 185677   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.85     |
| steps             | 185816   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.84     |
| steps             | 186018   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 186220   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 186368   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 186440   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 186576   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 186711   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 186841   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 187009   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.83     |
| steps             | 187160   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 187279   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 187346   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 187465   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 187643   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 187781   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 187983   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 188085   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 188232   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 188434   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 188496   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 188656   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 188839   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 188962   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 189101   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 189243   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 189393   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 189519   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 189668   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 189752   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 189897   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 190099   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 190214   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.82     |
| steps             | 190358   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 190428   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 190505   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 190648   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 190827   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 191001   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 191147   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 191248   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 191450   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 191652   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 191788   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 191913   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 192051   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 192195   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 192397   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 192563   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.81     |
| steps             | 192703   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 192905   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 193016   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 193203   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 193365   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 193517   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 193664   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 193821   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 193972   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 194174   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 194254   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 194430   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 194501   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 194703   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 194892   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 195055   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 195182   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 195281   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 195423   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 195494   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 195642   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 195802   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 195941   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 196116   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 196247   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 196412   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 196510   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 196712   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 196876   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 196976   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 197153   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 197348   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 197504   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 197633   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 197758   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 197896   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 198046   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 198232   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 198366   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 198504   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 198627   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 198786   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 198936   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 199138   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 199340   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 199477   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 199605   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 199758   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 199901   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 200061   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 200139   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 200216   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 200394   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 200526   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 200605   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 200711   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 200863   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.74     |
| steps             | 200926   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 201050   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 201177   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 201311   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 201470   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 201672   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 201736   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 201873   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.69     |
| steps             | 202050   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.69     |
| steps             | 202201   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 202403   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 202588   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 202741   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 202943   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 203060   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 203192   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 203316   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 203480   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 203577   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 203740   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 203899   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 204059   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 204216   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 204418   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 204542   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 204691   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 204842   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 204975   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 205139   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 205308   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 205446   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 205568   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 205704   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 205813   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 205937   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 206080   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 206227   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 206415   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 206570   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 206720   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.8      |
| steps             | 206903   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.79     |
| steps             | 206997   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 207172   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 207350   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 207495   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 207641   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.78     |
| steps             | 207810   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.77     |
| steps             | 208008   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 208123   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.76     |
| steps             | 208306   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.75     |
| steps             | 208489   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.73     |
| steps             | 208589   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 208687   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.71     |
| steps             | 208776   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.69     |
| steps             | 208878   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 209029   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 209119   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 209239   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.7      |
| steps             | 209387   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 209527   |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | 0.72     |
| steps             | 209643   |
| time_exploring    | 2        |
--------------------------------
