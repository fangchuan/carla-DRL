Logging to logs/openai-2019-03-27-15-49-19-486672
 the network use 2200375.0 varibales
--------------------------------
| episodes          | 20       |
| mean_100ep_reward | -0.52    |
| steps             | 1019     |
| time_exploring    | 90       |
--------------------------------
Saving model due to mean reward increase: None -> -0.52
--------------------------------
| episodes          | 40       |
| mean_100ep_reward | -0.48    |
| steps             | 2039     |
| time_exploring    | 80       |
--------------------------------
Saving model due to mean reward increase: -0.52 -> -0.48
--------------------------------
| episodes          | 60       |
| mean_100ep_reward | -0.81    |
| steps             | 3053     |
| time_exploring    | 70       |
--------------------------------
--------------------------------
| episodes          | 80       |
| mean_100ep_reward | -1.02    |
| steps             | 4073     |
| time_exploring    | 60       |
--------------------------------
--------------------------------
| episodes          | 100      |
| mean_100ep_reward | -0.7     |
| steps             | 5085     |
| time_exploring    | 50       |
--------------------------------
--------------------------------
| episodes          | 120      |
| mean_100ep_reward | -1.43    |
| steps             | 6044     |
| time_exploring    | 40       |
--------------------------------
--------------------------------
| episodes          | 140      |
| mean_100ep_reward | -2.3     |
| steps             | 6890     |
| time_exploring    | 32       |
--------------------------------
--------------------------------
| episodes          | 160      |
| mean_100ep_reward | -1.44    |
| steps             | 7686     |
| time_exploring    | 24       |
--------------------------------
--------------------------------
| episodes          | 180      |
| mean_100ep_reward | -1.63    |
| steps             | 8587     |
| time_exploring    | 15       |
--------------------------------
--------------------------------
| episodes          | 200      |
| mean_100ep_reward | -2.75    |
| steps             | 9371     |
| time_exploring    | 8        |
--------------------------------
--------------------------------
| episodes          | 220      |
| mean_100ep_reward | 0.98     |
| steps             | 10031    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: -0.48 -> 0.98
--------------------------------
| episodes          | 240      |
| mean_100ep_reward | 5.8      |
| steps             | 10655    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 0.98 -> 5.8
--------------------------------
| episodes          | 260      |
| mean_100ep_reward | 17.9     |
| steps             | 11575    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 5.8 -> 17.91
--------------------------------
| episodes          | 280      |
| mean_100ep_reward | 30.4     |
| steps             | 12470    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 17.91 -> 30.36
--------------------------------
| episodes          | 300      |
| mean_100ep_reward | 44.9     |
| steps             | 13419    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 30.36 -> 44.89
--------------------------------
| episodes          | 320      |
| mean_100ep_reward | 55.8     |
| steps             | 14353    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 44.89 -> 55.81
--------------------------------
| episodes          | 340      |
| mean_100ep_reward | 64.2     |
| steps             | 15232    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 55.81 -> 64.2
--------------------------------
| episodes          | 360      |
| mean_100ep_reward | 64.5     |
| steps             | 16117    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 64.2 -> 64.54
--------------------------------
| episodes          | 380      |
| mean_100ep_reward | 66.1     |
| steps             | 17038    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 64.54 -> 66.11
--------------------------------
| episodes          | 400      |
| mean_100ep_reward | 66.6     |
| steps             | 17978    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 66.11 -> 66.61
--------------------------------
| episodes          | 420      |
| mean_100ep_reward | 65.5     |
| steps             | 18916    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 440      |
| mean_100ep_reward | 66.8     |
| steps             | 19852    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 66.61 -> 66.84
--------------------------------
| episodes          | 460      |
| mean_100ep_reward | 67.9     |
| steps             | 20810    |
| time_exploring    | 2        |
--------------------------------
Saving model due to mean reward increase: 66.84 -> 67.89
--------------------------------
| episodes          | 480      |
| mean_100ep_reward | 66.5     |
| steps             | 21718    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 500      |
| mean_100ep_reward | 65.1     |
| steps             | 22636    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 520      |
| mean_100ep_reward | 65.6     |
| steps             | 23549    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 540      |
| mean_100ep_reward | 65.1     |
| steps             | 24494    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 560      |
| mean_100ep_reward | 64.7     |
| steps             | 25433    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 580      |
| mean_100ep_reward | 64.2     |
| steps             | 26332    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 600      |
| mean_100ep_reward | 63       |
| steps             | 27227    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 620      |
| mean_100ep_reward | 61.4     |
| steps             | 28119    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 640      |
| mean_100ep_reward | 62.2     |
| steps             | 29066    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 660      |
| mean_100ep_reward | 61.5     |
| steps             | 30013    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 680      |
| mean_100ep_reward | 62.1     |
| steps             | 30912    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 700      |
| mean_100ep_reward | 62.6     |
| steps             | 31818    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 720      |
| mean_100ep_reward | 64.3     |
| steps             | 32736    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 740      |
| mean_100ep_reward | 64.3     |
| steps             | 33687    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 760      |
| mean_100ep_reward | 64.4     |
| steps             | 34617    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 780      |
| mean_100ep_reward | 63.2     |
| steps             | 35523    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 800      |
| mean_100ep_reward | 62.8     |
| steps             | 36415    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 820      |
| mean_100ep_reward | 61.1     |
| steps             | 37327    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 840      |
| mean_100ep_reward | 59.6     |
| steps             | 38255    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 860      |
| mean_100ep_reward | 60.1     |
| steps             | 39189    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 880      |
| mean_100ep_reward | 61.1     |
| steps             | 40080    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 900      |
| mean_100ep_reward | 61.2     |
| steps             | 40938    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 920      |
| mean_100ep_reward | 63.2     |
| steps             | 41861    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 940      |
| mean_100ep_reward | 63.7     |
| steps             | 42816    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 960      |
| mean_100ep_reward | 62.5     |
| steps             | 43725    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 980      |
| mean_100ep_reward | 62.7     |
| steps             | 44638    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1000     |
| mean_100ep_reward | 63.5     |
| steps             | 45554    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1020     |
| mean_100ep_reward | 62.6     |
| steps             | 46501    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1040     |
| mean_100ep_reward | 61.9     |
| steps             | 47436    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1060     |
| mean_100ep_reward | 62.5     |
| steps             | 48391    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1080     |
| mean_100ep_reward | 64.6     |
| steps             | 49364    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1100     |
| mean_100ep_reward | 65.4     |
| steps             | 50300    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1120     |
| mean_100ep_reward | 65.8     |
| steps             | 51217    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1140     |
| mean_100ep_reward | 66.2     |
| steps             | 52123    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1160     |
| mean_100ep_reward | 65.6     |
| steps             | 53047    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1180     |
| mean_100ep_reward | 61.7     |
| steps             | 53978    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1200     |
| mean_100ep_reward | 61.6     |
| steps             | 54915    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1220     |
| mean_100ep_reward | 62.6     |
| steps             | 55867    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1240     |
| mean_100ep_reward | 59.5     |
| steps             | 56702    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1260     |
| mean_100ep_reward | 59.7     |
| steps             | 57626    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1280     |
| mean_100ep_reward | 61.4     |
| steps             | 58550    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1300     |
| mean_100ep_reward | 58.3     |
| steps             | 59403    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1320     |
| mean_100ep_reward | 55       |
| steps             | 60358    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1340     |
| mean_100ep_reward | 54.7     |
| steps             | 61342    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1360     |
| mean_100ep_reward | 49.8     |
| steps             | 62310    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1380     |
| mean_100ep_reward | 46.8     |
| steps             | 63297    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1400     |
| mean_100ep_reward | 46.6     |
| steps             | 64237    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1420     |
| mean_100ep_reward | 47.9     |
| steps             | 65137    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1440     |
| mean_100ep_reward | 49.6     |
| steps             | 66105    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1460     |
| mean_100ep_reward | 54.6     |
| steps             | 67039    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1480     |
| mean_100ep_reward | 51.6     |
| steps             | 67996    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1500     |
| mean_100ep_reward | 51.5     |
| steps             | 68952    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1520     |
| mean_100ep_reward | 46.9     |
| steps             | 69923    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1540     |
| mean_100ep_reward | 43.3     |
| steps             | 70927    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1560     |
| mean_100ep_reward | 37       |
| steps             | 71907    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1580     |
| mean_100ep_reward | 42.5     |
| steps             | 72892    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1600     |
| mean_100ep_reward | 42.6     |
| steps             | 73798    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1620     |
| mean_100ep_reward | 40.7     |
| steps             | 74798    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1640     |
| mean_100ep_reward | 45.6     |
| steps             | 75723    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1660     |
| mean_100ep_reward | 50.7     |
| steps             | 76675    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1680     |
| mean_100ep_reward | 49.2     |
| steps             | 77645    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1700     |
| mean_100ep_reward | 43.5     |
| steps             | 78634    |
| time_exploring    | 2        |
--------------------------------
--------------------------------
| episodes          | 1720     |
| mean_100ep_reward | 48.2     |
| steps             | 79619    |
| time_exploring    | 2        |
--------------------------------
